# Offline configuration - fully local operation
# Uses local Whisper STT, Fish Speech TTS, and optionally local LLM

mode: offline
stt_provider: whisper
tts_provider: fish_speech
echo_mode: false
streaming_mode: true
interruption_enabled: true

# Whisper settings for offline STT
whisper:
  model_size: small  # small offers good balance of speed/accuracy
  device: auto
  compute_type: auto

# Fish Speech TTS settings
fish_speech:
  voice_id: default
  default_speed: 1.0
  device: auto

# Local LLM settings (Ollama)
llm:
  provider: local
  model: llama3
  base_url: http://localhost:11434
  temperature: 0.7
  max_tokens: 1024
  system_prompt: "You are a helpful voice assistant. Keep responses concise and conversational."

# Audio settings
audio:
  input_sample_rate: 16000
  output_sample_rate: 44100
  chunk_duration_ms: 100

# VAD settings
vad:
  enabled: true
  threshold: 0.5
  min_speech_duration_ms: 250
  min_silence_duration_ms: 500
  padding_ms: 100
